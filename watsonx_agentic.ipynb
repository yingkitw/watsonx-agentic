{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'iam.cloud.ibm.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from watsonx import WatsonxAI\n",
    "\n",
    "proxy = \"proxy.us.ibm.com:8080\"\n",
    "\n",
    "wx = WatsonxAI()\n",
    "wx.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some basic classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    name = \"Agent\"\n",
    "    model = \"ibm/granite-13b-chat-v2\"\n",
    "    instructions = [\"You are a helpful agent.\"]\n",
    "    functions = []\n",
    "    tool_choice = None\n",
    "    parallel_tool_calls = True\n",
    "\n",
    "\n",
    "class Response:\n",
    "    messages = []\n",
    "    agent = None\n",
    "    context_variables = {}\n",
    "\n",
    "\n",
    "class Result:\n",
    "    value = \"\"\n",
    "    agent = None\n",
    "    context_variables = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_plan(requirement):\n",
    "    prompt = f\"\"\"[INST]\n",
    "please generate a concise and solid plan to satisfy the requirement provided.\n",
    "-understand the requirement in detail.\n",
    "-list out what knowlege you need to satisfy the requirement.\n",
    "-think logically.\n",
    "-think step by step.\n",
    "-you trust the result of the tools more than your memory.\n",
    "-you trust the knowledge provide more than your memory.\n",
    "-leverage tool if possible.\n",
    "-dont guess.\n",
    "-please breakdown complex task to simple tasks.\n",
    "-DONT generate result of the steps.\n",
    "-**DONT** generate **Final Result:**\n",
    "<<SYS>>\n",
    "requirement: `{requirement}`\n",
    "<</SYS>>\n",
    "[/INST]plan:\"\"\"\n",
    "\n",
    "    return wx.watsonx_gen(prompt,wx.LLAMA_3_70B_INSTRUCT).replace(\"```\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_summary(requirement,answer):\n",
    "    prompt = f\"\"\"[INST]\n",
    "please generate a complete sentence summary base on the answer provided only.\n",
    "-use simple english.\n",
    "-dont guess.\n",
    "<<SYS>>\n",
    "requirement: `{requirement}`\n",
    "answer: `{answer}`\n",
    "<</SYS>>\n",
    "[/INST]answer summary:\"\"\"\n",
    "\n",
    "    return wx.watsonx_gen(prompt,wx.LLAMA_3_70B_INSTRUCT).replace(\"```\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = \"\"\"[\n",
    "    get_hko_weather()->str,\n",
    "    query_duckduckgo(query:str)->str,\n",
    "    search_arxiv(query:str)->str,\n",
    "    query_wikipedia(title:str)->str\n",
    "]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_code(requirement,plan):\n",
    "    prompt = f\"\"\"[INST]\n",
    "please generate python code that execute the plan to fulfill the requirement.\n",
    "-ensure the python generated is executable.\n",
    "-clean up if any unneccessary characters.\n",
    "-you can use the tool provided directly without define it.\n",
    "-understand the plan in detail. dont miss the steps.\n",
    "-**DONT** use SaaS service which need API KEY.\n",
    "-**DONT** catch error.\n",
    "-raise error when hit problem.\n",
    "-**DONT** throw SystemExit\n",
    "-**DONT** generate main().\n",
    "-**DONT** generate explanation.\n",
    "-generate the code directly.\n",
    "-generate the code only.\n",
    "<<SYS>>\n",
    "requirement: `{requirement}`\n",
    "plan: `{plan}`\n",
    "tools: {tools}\n",
    "<</SYS>>\n",
    "[/INST]\n",
    "```python\n",
    "\"\"\"\n",
    "    \n",
    "    #-dont define function.\n",
    "\n",
    "    return wx.watsonx_gen(prompt,wx.LLAMA_3_70B_INSTRUCT).replace(\"```\",\"\")\n",
    "    # print(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def revise_code(code, plan, error):\n",
    "    prompt = f\"\"\"[INST]\n",
    "revise the code provided.\n",
    "-review the problem in the code and the error.\n",
    "-prevent the error from the code.\n",
    "-you can use the tool provided directly without define it.\n",
    "-understand the plan in detail. dont miss the steps.\n",
    "-**DONT** use SaaS service which need API KEY.\n",
    "-**DONT** catch error.\n",
    "-raise error when hit problem. \n",
    "-**DONT** throw SystemExit\n",
    "-**DONT** generate main().\n",
    "-**DONT** generate explanation.\n",
    "-generate the code directly.\n",
    "-generate the code only.\n",
    "<<SYS>>\n",
    "code: `{code}`\n",
    "plan: `{plan}`\n",
    "error: `{error}`\n",
    "tools: {tools}\n",
    "<</SYS>>\n",
    "[/INST]\n",
    "fixed code:```python\"\"\"\n",
    "\n",
    "    answer = wx.watsonx_gen(prompt,wx.LLAMA_3_70B_INSTRUCT).replace(\"```\",\"\")\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import sys\n",
    "import traceback\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "def call_tool(module_import, function_call, max_traceback_lines=5):\n",
    "    # Create StringIO objects to capture standard output and error output\n",
    "    output_stream = io.StringIO()\n",
    "    error_stream = io.StringIO()\n",
    "\n",
    "    # Get the current interactive shell\n",
    "    shell = InteractiveShell.instance()\n",
    "\n",
    "    # Redirect stdout and stderr\n",
    "    old_stdout = sys.stdout\n",
    "    old_stderr = sys.stderr\n",
    "    sys.stdout = output_stream\n",
    "    sys.stderr = error_stream\n",
    "\n",
    "    output = None\n",
    "    error = None\n",
    "\n",
    "    # Using exec to import the module and evaluate the function call\n",
    "    try:\n",
    "        local_namespace = {}\n",
    "        exec(module_import, local_namespace, local_namespace)  # Dynamically import the module\n",
    "        print(f\"|{function_call}|\")\n",
    "        exec(function_call, local_namespace, local_namespace)  # Evaluate the function call\n",
    "    except ImportError as e:\n",
    "        error = f\"Import Error: {str(e)}\"\n",
    "    except Exception as e:\n",
    "        # Capture the traceback for more detailed error information\n",
    "        full_traceback = traceback.format_exc().strip()\n",
    "        # Limit the traceback to the last 'max_traceback_lines' lines\n",
    "        limited_traceback = \"\\n\".join(full_traceback.splitlines()[-max_traceback_lines:])\n",
    "        error = f\"Unexpected Error: {str(e)}\\n{limited_traceback}\"\n",
    "    finally:\n",
    "        # Reset stdout to its original state\n",
    "        sys.stdout = old_stdout\n",
    "        sys.stderr = old_stderr\n",
    "\n",
    "    # Get the output from the output_stream\n",
    "    output = output_stream.getvalue().strip()\n",
    "    error_output = error_stream.getvalue().strip()\n",
    "\n",
    "    # Check the output or error\n",
    "    if error:\n",
    "        return f\"Output: {output}\", f\"Error: {error}\"\n",
    "    elif error_output:\n",
    "        return f\"Output: {output}\", f\"Error Output: {error_output}\"\n",
    "    else:\n",
    "        return f\"Output: {output}\", None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_output(question, stdout):\n",
    "    prompt = f\"\"\"[INST]classify if stdout include error.\n",
    "-show sucess or fail only, but nothing else.\n",
    "-show success if include no error. and end the generation.\n",
    "-show fail if include error. and end the generation.\n",
    "<<SYS>>\n",
    "question: `{question}`\n",
    "stdout: `{stdout}`\n",
    "<</SYS>>\n",
    "[/INST]success or fail:\"\"\"\n",
    "    success = wx.watsonx_gen(prompt,wx.LLAMA_3_70B_INSTRUCT)\n",
    "    # print(success)\n",
    "    return success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agentic_prompt(requirement, max_turns=10,debug=False):\n",
    "    # Generate initial action and code\n",
    "    plan = gen_plan(requirement)\n",
    "    if debug:\n",
    "        print(f\"#1: {plan}\")\n",
    "    code = gen_code(requirement, plan)\n",
    "    if debug:\n",
    "        print(f\"#2: <|{code}|>\")\n",
    "\n",
    "    output = \"\"\n",
    "\n",
    "    # Loop until the review output is empty\n",
    "    for turn in range(max_turns):\n",
    "        print(f\"turn #{turn+1} ---\")\n",
    "        # output = exec_with_output(code)\n",
    "        output, error = call_tool(\"\",code)\n",
    "        if debug:\n",
    "            print(f\"#3: {output}\")\n",
    "        \n",
    "        if error is None:\n",
    "            break\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"error {error}\")\n",
    "        # review = eval_output(requirement, output)\n",
    "        # if debug:\n",
    "        #     print(f\"#4: {review}\")\n",
    "        \n",
    "        # if \"success\" in review:  # Exit if review output is empty\n",
    "        #     # print(f\"#final result: {output}\")\n",
    "        #     break\n",
    "        \n",
    "        revised = revise_code(code, plan, error)\n",
    "        if debug:\n",
    "            print(f\"#5: {revised}\")\n",
    "\n",
    "        # Update code for the next iteration\n",
    "        code = revised\n",
    "\n",
    "    summary = gen_summary(requirement,output)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = agentic_prompt(\"how is weather today in Hong Kong, base on HKO\",debug=True)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = agentic_prompt(\"what is the population in hong kong\",debug=True)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = agentic_prompt(\"how many prime number with in 10000\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = agentic_prompt(\"how many R in straberry, not regarding to upper lower case\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = agentic_prompt(\"in math, compare 9.11 with 9.8\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = agentic_prompt(\"tell me Hong Kong time\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_agent = None\n",
    "context_variables = []\n",
    "history = [] \n",
    "init_len = 0\n",
    "\n",
    "max_turns = 10\n",
    "model_id = wx.GRANITE_20B_CODE_INSTRUCT\n",
    "tools = []\n",
    "messages = []\n",
    "active_agent = Agent(model_id,\"do math\")\n",
    "while len(history) - init_len < max_turns:\n",
    "    message = \"\"\n",
    "    partial_response = watsonx.watsonx_gen(message,history)\n",
    "    history.append(message)\n",
    "    history.append(partial_response.message)\n",
    "    context_variables.update(partial_response.ontext_variable)\n",
    "    active_agent = partial_response.agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clock():\n",
    "    print(\"12pm\")\n",
    "    return \"12pm\"\n",
    "\n",
    "def calculate(expression):\n",
    "    return eval(expression)\n",
    "\n",
    "prompt = f\"\"\"[INST]\n",
    "tell me 3434 * 21 / 32\n",
    "-for any math question, dont base on memory. ride on tool.\n",
    "-tell what you confidence to answer, dont guess.\n",
    "-generate the python code to use tool in need.\n",
    "-only use the tool provided.\n",
    "-dont repeat.\n",
    "-generate the answer or code only.\n",
    "<<SYS>>\n",
    "tools: [\n",
    "    clock()->str #get time,\n",
    "    abc(code:str)->str #get stock price, \n",
    "    calculator(expression:str)->str,\n",
    "    browser(url:str)->str\n",
    "    ]\n",
    "<</SYS>>\n",
    "[/INST]answer:\n",
    "\"\"\"\n",
    "\n",
    "answer = wx.watsonx_gen(prompt,wx.LLAMA_3_70B_INSTRUCT)\n",
    "print(answer)\n",
    "out = call_tool(\"\",answer.strip())\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(3434 * 21 / 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clock():\n",
    "    print(\"12pm\")\n",
    "    return \"12pm\"\n",
    "\n",
    "def ask_granite(question):\n",
    "    prompt = f\"\"\"<|system|>\n",
    "-tell what you confidence to answer only, dont guess.\n",
    "-select the right tool.\n",
    "-dont base on memory. call the right tool in contenxt.\n",
    "[TOOLS]\n",
    "tools: [\n",
    "    clock()->str #get time,\n",
    "    abc(code:str)->str #get stock price, \n",
    "    calculator(expression:str)->str # do math,\n",
    "    browser(url:str)->str #find informatino\n",
    "    ]\n",
    "[/TOOLS]\n",
    "-generate the python code to use tool in need.\n",
    "-only use the tool provided.\n",
    "-dont repeat.\n",
    "-generate the answer or code only.\n",
    "-dont generate result.\n",
    "-dont generate Calculation steps.\n",
    "-generate the code only.\n",
    "<|user|>\n",
    "{question}\n",
    "<|assistant|>\n",
    "```python\"\"\"\n",
    "\n",
    "    answer = wx.watsonx_gen(prompt,wx.GRANITE_13B_CHAT_V2)\n",
    "    return answer\n",
    "\n",
    "answer = ask_granite(\"tell me the content of cnn.com today\")\n",
    "print(answer)\n",
    "\n",
    "answer = ask_granite(\"tell me 320*232 / 2322\")\n",
    "print(answer)\n",
    "\n",
    "answer = ask_granite(\"tell me about paris\")\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
