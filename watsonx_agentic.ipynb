{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'iam.cloud.ibm.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from watsonx import WatsonxAI\n",
    "\n",
    "proxy = \"proxy.us.ibm.com:8080\"\n",
    "\n",
    "wx = WatsonxAI()\n",
    "wx.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import sys\n",
    "import traceback\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "def call_tool(module_import, function_call, max_traceback_lines=5):\n",
    "    # Create StringIO objects to capture standard output and error output\n",
    "    output_stream = io.StringIO()\n",
    "    error_stream = io.StringIO()\n",
    "\n",
    "    # Get the current interactive shell\n",
    "    shell = InteractiveShell.instance()\n",
    "\n",
    "    # Redirect stdout and stderr\n",
    "    old_stdout = sys.stdout\n",
    "    old_stderr = sys.stderr\n",
    "    sys.stdout = output_stream\n",
    "    sys.stderr = error_stream\n",
    "\n",
    "    output = None\n",
    "    error = None\n",
    "\n",
    "    # Using exec to import the module and evaluate the function call\n",
    "    try:\n",
    "        local_namespace = {}\n",
    "        exec(module_import, local_namespace, local_namespace)  # Dynamically import the module\n",
    "        print(f\"|{function_call}|\")\n",
    "        exec(function_call, local_namespace, local_namespace)  # Evaluate the function call\n",
    "    except ImportError as e:\n",
    "        error = f\"Import Error: {str(e)}\"\n",
    "    except Exception as e:\n",
    "        # Capture the traceback for more detailed error information\n",
    "        full_traceback = traceback.format_exc().strip()\n",
    "        # Limit the traceback to the last 'max_traceback_lines' lines\n",
    "        limited_traceback = \"\\n\".join(full_traceback.splitlines()[-max_traceback_lines:])\n",
    "        error = f\"Unexpected Error: {str(e)}\\n{limited_traceback}\"\n",
    "    finally:\n",
    "        # Reset stdout to its original state\n",
    "        sys.stdout = old_stdout\n",
    "        sys.stderr = old_stderr\n",
    "\n",
    "    # Get the output from the output_stream\n",
    "    output = output_stream.getvalue().strip()\n",
    "    error_output = error_stream.getvalue().strip()\n",
    "\n",
    "    # Check the output or error\n",
    "    if error:\n",
    "        return f\"Output: {output}\", f\"Error: {error}\"\n",
    "    elif error_output:\n",
    "        return f\"Output: {output}\", f\"Error Output: {error_output}\"\n",
    "    else:\n",
    "        return f\"Output: {output}\", None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    name = \"Agent\"\n",
    "    nextAgent = None\n",
    "    debug = False\n",
    "    model_id = \"\"\n",
    "    system_prompt = [\"You are a helpful agent.\"]\n",
    "    functions = []\n",
    "    tool_choice = None\n",
    "    parallel_tool_calls = True\n",
    "    input_names = []\n",
    "    output_name = []\n",
    "    prompt = \"\"\n",
    "\n",
    "    def __init__(self,name,prompt,input_names, output_name, model_id=wx.GRANOTE_3_8B_INSTRUCT, debug=False):\n",
    "        self.name = name\n",
    "        self.prompt = prompt\n",
    "        self.input_names = input_names\n",
    "        self.output_name = output_name\n",
    "        self.model_id = model_id\n",
    "        self.debug = debug\n",
    "\n",
    "    def run(self,context,history):\n",
    "        print(f\"{self.name} running\")\n",
    "        cur_prompt = self.prompt;\n",
    "        for name in self.input_names:\n",
    "            if name in context:\n",
    "                cur_prompt = cur_prompt.replace(f\"{{{name}}}\",context[name])\n",
    "\n",
    "        cur_prompt = cur_prompt.replace(\"{history}\",str(history))\n",
    "        if self.debug:\n",
    "            print(cur_prompt)\n",
    "        answer = wx.watsonx_gen(cur_prompt,wx.GRANOTE_3_8B_INSTRUCT).replace(\"```\",\"\")\n",
    "        entry = f\"\"\"{{\n",
    "                           agent:`{self.name}`,\n",
    "                           input:`{context}`,\n",
    "                           output:`{answer}`}}\"\"\"\n",
    "        history.append(entry)\n",
    "        if self.debug:\n",
    "            print(entry)\n",
    "        context[self.output_name] = answer\n",
    "        return answer\n",
    "\n",
    "planningAgent = Agent(\n",
    "    name = \"Planning Agent\",\n",
    "    prompt = \"\"\"[INST]\n",
    "please generate a concise and solid plan to satisfy the requirement provided.\n",
    "-understand the requirement in detail.\n",
    "-list out what knowlege you need to satisfy the requirement.\n",
    "-think logically.\n",
    "-think step by step.\n",
    "-you trust the result of the tools more than your memory.\n",
    "-you trust the knowledge provide more than your memory.\n",
    "-leverage tool if possible.\n",
    "-dont guess.\n",
    "-please breakdown complex task to simple tasks.\n",
    "-DONT generate result of the steps.\n",
    "-**DONT** generate **Final Result:**\n",
    "<<SYS>>\n",
    "requirement: `{requirement}`\n",
    "<</SYS>>\n",
    "[/INST]plan:\"\"\",\n",
    "    input_names = [\"requirement\"],\n",
    "    output_name = \"plan\"\n",
    ")\n",
    "\n",
    "triageAgent = Agent(\n",
    "    name = \"Triage Agent\",\n",
    "    prompt = \"\"\"[INST]\n",
    "you are triager to determine who will be the next agent to handle the task.\n",
    "please make your best judgement base on the history and agent available.\n",
    "<<SYS>>\n",
    "history: `{history}`\n",
    "agents: {agents}\n",
    "[/INST]agent:\"\"\",\n",
    "    input_names = [\"history\",\"agents\"],\n",
    "    output_name = \"next\"\n",
    ")\n",
    "\n",
    "codingAgent = Agent(\n",
    "    name = \"Coding Agent\",\n",
    "    prompt = \"\"\"[INST]\n",
    "please generate python code that execute the plan to fulfill the requirement.\n",
    "-ensure the python generated is executable.\n",
    "-clean up if any unneccessary characters.\n",
    "-review the problem in the code and the error if provided.\n",
    "-prevent the error from the code if provided.\n",
    "-you can use the tool provided directly without define it.\n",
    "-understand the plan in detail. dont miss the steps.\n",
    "-**DONT** use SaaS service which need API KEY.\n",
    "-**DONT** catch error.\n",
    "-raise error when hit problem.\n",
    "-**DONT** throw SystemExit\n",
    "-**DONT** generate main().\n",
    "-**DONT** generate explanation.\n",
    "-generate the code directly.\n",
    "-generate the code only.\n",
    "<<SYS>>\n",
    "requirement: `{requirement}`\n",
    "code with problem: `{code}`\n",
    "plan: `{plan}`\n",
    "error: `{error}`\n",
    "tools: [\n",
    "    get_hko_weather()->str,\n",
    "    query_duckduckgo(query:str)->str,\n",
    "    search_arxiv(query:str)->str,\n",
    "    query_wikipedia(title:str)->str\n",
    "]\n",
    "<</SYS>>\n",
    "[/INST]\n",
    "```python\n",
    "\"\"\",\n",
    "    input_names = [\"requirement\",\"plan\",\"error\"],\n",
    "    output_name = \"code\"\n",
    ")\n",
    "\n",
    "# reviseAgent = Agent(\n",
    "#     name = \"Revise Agent\",\n",
    "#     prompt = \"\"\"[INST]\n",
    "# revise the code provided.\n",
    "# -review the problem in the code and the error.\n",
    "# -prevent the error from the code.\n",
    "# -you can use the tool provided directly without define it.\n",
    "# -understand the plan in detail. dont miss the steps.\n",
    "# -**DONT** use SaaS service which need API KEY.\n",
    "# -**DONT** catch error.\n",
    "# -raise error when hit problem. \n",
    "# -**DONT** throw SystemExit\n",
    "# -**DONT** generate main().\n",
    "# -**DONT** generate explanation.\n",
    "# -generate the code directly.\n",
    "# -generate the code only.\n",
    "# <<SYS>>\n",
    "# code: `{code}`\n",
    "# plan: `{plan}`\n",
    "# error: `{error}`\n",
    "# tools: [\n",
    "#     get_hko_weather()->str,\n",
    "#     query_duckduckgo(query:str)->str,\n",
    "#     search_arxiv(query:str)->str,\n",
    "#     query_wikipedia(title:str)->str\n",
    "# ]\n",
    "# <</SYS>>\n",
    "# [/INST]\n",
    "# fixed code:```python\"\"\",\n",
    "#     input_names = [\"code\",\"plan\",\"error\"],\n",
    "#     output_name = \"revised\"\n",
    "# )\n",
    "\n",
    "executeAgent = Agent(\n",
    "    name = \"Execute Agent\",\n",
    "    prompt = \"\",\n",
    "    input_names = [],\n",
    "    output_name = \"\"\n",
    ")\n",
    "\n",
    "evalAgent = Agent(\n",
    "    name = \"Evaluate Agent\",\n",
    "        prompt = \"\"\"[INST]classify if stdout include error.\n",
    "-show sucess or fail only, but nothing else.\n",
    "-show success if include no error. and end the generation.\n",
    "-show fail if include error. and end the generation.\n",
    "<<SYS>>\n",
    "question: `{question}`\n",
    "stdout: `{stdout}`\n",
    "<</SYS>>\n",
    "[/INST]success or fail:\"\"\",\n",
    "    input_names = [\"question\",\"stdout\"],\n",
    "    output_name = \"eval\"\n",
    ")\n",
    "\n",
    "summaryAgent = Agent(\n",
    "    name = \"Summary Agent\",\n",
    "    prompt= \"\"\"[INST]\n",
    "please generate a complete sentence summary base on the answer provided only.\n",
    "-dont use your common sense.\n",
    "-only base on the answer provided.\n",
    "-use simple english.\n",
    "-dont guess.\n",
    "<<SYS>>\n",
    "requirement: `{requirement}`\n",
    "answer: `{output}`\n",
    "<</SYS>>\n",
    "[/INST]answer summary:\"\"\",\n",
    "    input_names = [\"requirement\",\"output\"],\n",
    "    output_name = \"summary\"\n",
    ")\n",
    "    \n",
    "class AgenticPlaygroud:\n",
    "    watsonxAI = None\n",
    "    history = []\n",
    "    context = {}\n",
    "    agents = []\n",
    "    activeAgent = None\n",
    "    tools = []\n",
    "    messages = []\n",
    "\n",
    "    def __init__(self,watsonxAI):\n",
    "        self.watsonxAI = watsonxAI\n",
    "\n",
    "    def run(self,input):\n",
    "        self.active_agent = Agent(self.model_id,requirement)\n",
    "        while len(self.history) < self.maxTurns:\n",
    "            requirement = \"\"\n",
    "            output, vars, nextAgent = self.watsonxAI.watsonx_gen(input,self.history)\n",
    "            self.history.append(input)\n",
    "            self.history.append(output)\n",
    "            self.context.update(vars)\n",
    "            self.active_agent = nextAgent\n",
    "\n",
    "    def agentic_prompt(self, requirement, max_turns=10,debug=False):\n",
    "        self.context = {\n",
    "            \"requirement\": requirement\n",
    "        }\n",
    "        self.history = []\n",
    "        # Generate initial action and code\n",
    "        planningAgent.run(self.context,self.history)\n",
    "        \n",
    "        # Loop until the review output is empty\n",
    "        for turn in range(max_turns):\n",
    "            print(f\"turn #{turn+1} ---\")\n",
    "            # output = exec_with_output(code)\n",
    "            codingAgent.run(self.context,self.history)\n",
    "            self.context['output'], self.context['error'] = call_tool(\"\",self.context['code'])\n",
    "            if debug:\n",
    "                print(f\"#3: {self.context['output']}\")\n",
    "            \n",
    "            if self.context['error'] is None:\n",
    "                break\n",
    "            \n",
    "            if debug:\n",
    "                print(f\"error {self.context['error']}\")\n",
    "            # review = eval_output(requirement, output)\n",
    "            # if debug:\n",
    "            #     print(f\"#4: {review}\")\n",
    "            \n",
    "            # if \"success\" in review:  # Exit if review output is empty\n",
    "            #     # print(f\"#final result: {output}\")\n",
    "            #     break\n",
    "\n",
    "        summaryAgent.run(self.context,self.history)\n",
    "        return self.context['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = \"\"\"[\n",
    "    get_hko_weather()->str,\n",
    "    query_duckduckgo(query:str)->str,\n",
    "    search_arxiv(query:str)->str,\n",
    "    query_wikipedia(title:str)->str\n",
    "]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = AgenticPlaygroud(wx).agentic_prompt(\"how is weather today in Hong Kong, base on HKO\",debug=True)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = AgenticPlaygroud(wx).agentic_prompt(\"what is the population in hong kong\",debug=True)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = AgenticPlaygroud(wx).agentic_prompt(\"what is stock price for IBM today\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planning Agent running\n",
      "turn #1 ---\n",
      "Coding Agent running\n",
      "Summary Agent running\n",
      " There are 1229 prime numbers within 10000.\n"
     ]
    }
   ],
   "source": [
    "output = AgenticPlaygroud(wx).agentic_prompt(\"how many prime number with in 10000\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planning Agent running\n",
      "turn #1 ---\n",
      "Coding Agent running\n",
      "Summary Agent running\n",
      " There are 3 R's in the word \"strawberry\".\n"
     ]
    }
   ],
   "source": [
    "output = AgenticPlaygroud(wx).agentic_prompt(\"how many R in straberry, not regarding to upper lower case\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planning Agent running\n",
      "turn #1 ---\n",
      "Coding Agent running\n",
      "Summary Agent running\n",
      " 9.11 is not greater than 9.8.\n"
     ]
    }
   ],
   "source": [
    "output = AgenticPlaygroud(wx).agentic_prompt(\"in math, compare 9.11 with 9.8\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planning Agent running\n",
      "turn #1 ---\n",
      "Coding Agent running\n",
      "turn #2 ---\n",
      "Coding Agent running\n",
      "Summary Agent running\n",
      " The current time in Hong Kong is 2024-10-21 22:11:54 HKT+0800.\n"
     ]
    }
   ],
   "source": [
    "output = AgenticPlaygroud(wx).agentic_prompt(\"tell me Hong Kong time\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planning Agent running\n",
      "turn #1 ---\n",
      "Coding Agent running\n",
      "Summary Agent running\n",
      " The function tells about Paris by querying Wikipedia for geographical,, historical, cultural, and tourist information.\n"
     ]
    }
   ],
   "source": [
    "output = AgenticPlaygroud(wx).agentic_prompt(\"tell me about Paris\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planning Agent running\n",
      "turn #1 ---\n",
      "Coding Agent running\n",
      "Summary Agent running\n",
      " The result of 320*232 divided by 2322 is 31.97.\n"
     ]
    }
   ],
   "source": [
    "output = AgenticPlaygroud(wx).agentic_prompt(\"give me answer of 320*232 / 2322, keep 2 decimal point only.\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planning Agent running\n",
      "turn #1 ---\n",
      "Coding Agent running\n",
      "Summary Agent running\n",
      " The biggest planet in the solar system is Jupiter.\n"
     ]
    }
   ],
   "source": [
    "output = AgenticPlaygroud(wx).agentic_prompt(\"tell me the biggest planet in solar system\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clock():\n",
    "    print(\"12pm\")\n",
    "    return \"12pm\"\n",
    "\n",
    "def calculate(expression):\n",
    "    return eval(expression)\n",
    "\n",
    "prompt = f\"\"\"[INST]\n",
    "tell me 3434 * 21 / 32\n",
    "-for any math question, dont base on memory. ride on tool.\n",
    "-tell what you confidence to answer, dont guess.\n",
    "-generate the python code to use tool in need.\n",
    "-only use the tool provided.\n",
    "-dont repeat.\n",
    "-generate the answer or code only.\n",
    "<<SYS>>\n",
    "tools: [\n",
    "    clock()->str #get time,\n",
    "    abc(code:str)->str #get stock price, \n",
    "    calculator(expression:str)->str,\n",
    "    browser(url:str)->str\n",
    "    ]\n",
    "<</SYS>>\n",
    "[/INST]answer:\n",
    "\"\"\"\n",
    "\n",
    "answer = wx.watsonx_gen(prompt,wx.LLAMA_3_70B_INSTRUCT)\n",
    "print(answer)\n",
    "out = call_tool(\"\",answer.strip())\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(320*232 / 2322)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clock():\n",
    "    print(\"12pm\")\n",
    "    return \"12pm\"\n",
    "\n",
    "def ask_granite(question):\n",
    "    prompt = f\"\"\"<|system|>\n",
    "-tell what you confidence to answer only, dont guess.\n",
    "-select the right tool.\n",
    "-dont base on memory. call the right tool in contenxt.\n",
    "[TOOLS]\n",
    "tools: [\n",
    "    clock()->str #get time,\n",
    "    abc(code:str)->str #get stock price, \n",
    "    calculator(expression:str)->str # do math,\n",
    "    browser(url:str)->str #find informatino\n",
    "    ]\n",
    "[/TOOLS]\n",
    "-generate the python code to use tool in need.\n",
    "-only use the tool provided.\n",
    "-dont repeat.\n",
    "-generate the answer or code only.\n",
    "-dont generate result.\n",
    "-dont generate Calculation steps.\n",
    "-generate the code only.\n",
    "<|user|>\n",
    "{question}\n",
    "<|assistant|>\n",
    "```python\"\"\"\n",
    "\n",
    "    answer = wx.watsonx_gen(prompt,wx.GRANITE_13B_CHAT_V2)\n",
    "    return answer\n",
    "\n",
    "answer = ask_granite(\"tell me the content of cnn.com today\")\n",
    "print(answer)\n",
    "\n",
    "answer = ask_granite(\"tell me 320*232 / 2322\")\n",
    "print(answer)\n",
    "\n",
    "answer = ask_granite(\"tell me about paris\")\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
